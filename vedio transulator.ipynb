{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXqnmclVX+O1frzM5sFgGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marankri/sakthimaran/blob/main/vedio%20transulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "rvnFBj2XwDRD",
        "outputId": "fbb908bb-199f-4e5c-e50f-34d87f3cbcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/800.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n",
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 44.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://56699c41fa0c44d822.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://56699c41fa0c44d822.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "# Install required libraries\n",
        "!pip install gradio transformers torch gtts moviepy openai-whisper --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import gradio as gr\n",
        "import moviepy.editor as mp\n",
        "import os\n",
        "from gtts import gTTS\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load Whisper model (this may take a moment)\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# Define translation models for South Indian languages and their gTTS language codes\n",
        "translation_models = {\n",
        "    \"English to Tamil\": {\"model\": \"Helsinki-NLP/opus-mt-en-ta\", \"tts_lang\": \"ta\"},\n",
        "    \"English to Telugu\": {\"model\": \"Helsinki-NLP/opus-mt-en-te\", \"tts_lang\": \"te\"},\n",
        "    \"English to Kannada\": {\"model\": \"Helsinki-NLP/opus-mt-en-kn\", \"tts_lang\": \"kn\"},\n",
        "    \"English to Malayalam\": {\"model\": \"Helsinki-NLP/opus-mt-en-ml\", \"tts_lang\": \"ml\"}\n",
        "}\n",
        "\n",
        "def process_video(video_file, target_language):\n",
        "    # Save the uploaded video file\n",
        "    input_video_path = \"input_video.mp4\"\n",
        "    with open(input_video_path, \"wb\") as f:\n",
        "        f.write(video_file.read())\n",
        "\n",
        "    # Load the video using MoviePy and extract its audio\n",
        "    video_clip = mp.VideoFileClip(input_video_path)\n",
        "    audio_path = \"extracted_audio.wav\"\n",
        "    video_clip.audio.write_audiofile(audio_path, logger=None)\n",
        "\n",
        "    # Transcribe the audio using Whisper\n",
        "    transcription_result = whisper_model.transcribe(audio_path)\n",
        "    original_text = transcription_result[\"text\"]\n",
        "\n",
        "    # Set up the translation pipeline using the selected model\n",
        "    model_name = translation_models[target_language][\"model\"]\n",
        "    translator = pipeline(\"translation\", model=model_name)\n",
        "    translation = translator(original_text)[0][\"translation_text\"]\n",
        "\n",
        "    # Generate new speech (TTS) for the translated text using gTTS\n",
        "    tts_language = translation_models[target_language][\"tts_lang\"]\n",
        "    tts = gTTS(text=translation, lang=tts_language)\n",
        "    tts_audio_path = \"translated_audio.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    # Load the generated TTS audio and set it as the audio for the original video\n",
        "    new_audio = mp.AudioFileClip(tts_audio_path)\n",
        "    # Note: The new audio length may differ from the original. Here we set the new audio and cut or loop as needed.\n",
        "    # For simplicity, we use the new audio as-is.\n",
        "    final_video = video_clip.set_audio(new_audio)\n",
        "    output_video_path = \"translated_video.mp4\"\n",
        "    final_video.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
        "\n",
        "    # Clean up temporary files if needed\n",
        "    # os.remove(input_video_path)\n",
        "    # os.remove(audio_path)\n",
        "    # os.remove(tts_audio_path)\n",
        "\n",
        "    return output_video_path\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=[\n",
        "        gr.Video(label=\"Input Video (English)\"),\n",
        "        gr.Dropdown(choices=list(translation_models.keys()), label=\"Select Target Language\")\n",
        "    ],\n",
        "    outputs=gr.Video(label=\"Translated Video\"),\n",
        "    title=\"Video Translator with TTS\",\n",
        "    description=(\"Upload a video with English speech. The system will transcribe, translate to a South Indian language, \"\n",
        "                 \"generate new speech for the translation, and output a video with the new audio track.\")\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch(share=True)"
      ]
    }
  ]
}